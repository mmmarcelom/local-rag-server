# Local RAG Server

Sistema de chatbot inteligente para WhatsApp com RAG (Retrieval-Augmented Generation) usando FastAPI, Supabase, Qdrant e Ollama.

## ğŸš€ CaracterÃ­sticas

- **Chatbot WhatsApp**: IntegraÃ§Ã£o via WTS.chat API
- **RAG System**: Busca vetorial com Qdrant + embeddings
- **IA Local**: Ollama com modelos de linguagem
- **Banco de Dados**: Supabase (PostgreSQL)
- **ConcorrÃªncia**: Background tasks + load balancing
- **Docker**: Containers isolados e escalÃ¡veis

## ğŸ“‹ PrÃ©-requisitos

- Docker e Docker Compose
- Python 3.11+
- 8GB+ RAM (recomendado)
- GPU (opcional, para aceleraÃ§Ã£o)

## ğŸ› ï¸ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio
```bash
git clone <repository-url>
cd local-rag-server
```

### 2. Configure as variÃ¡veis de ambiente
```bash
# Windows (CMD)
copy env.example .env

# Windows (PowerShell)
copy env.example .env

# Linux/Mac
cp env.example .env
```

### 3. Edite o arquivo .env
Configure as seguintes variÃ¡veis no arquivo `.env`:

```bash
# ConfiguraÃ§Ãµes do WhatsApp API (WTS.chat) - OBRIGATÃ“RIO
WTS_API_TOKEN=your_wts_api_token_here

# As outras configuraÃ§Ãµes jÃ¡ vÃªm com valores padrÃ£o para desenvolvimento
```

**âš ï¸ Importante**: VocÃª precisa obter um token da API WTS.chat para que o WhatsApp funcione.

### 4. Escolha o modo de execuÃ§Ã£o

#### **Modo Teste (1 Ollama - Recomendado para desenvolvimento)**
```bash
docker-compose --profile single-ollama up -d
```

#### **Modo ProduÃ§Ã£o (3 Ollamas + Load Balancer)**
```bash
docker-compose --profile multi-ollama up -d
```

### 5. Verificar se tudo estÃ¡ funcionando
```bash
# Verificar status dos containers
docker-compose ps

# Ver logs
docker-compose logs -f

# Acessar documentaÃ§Ã£o da API
# http://localhost:8000/docs
```

## ğŸ–¥ï¸ **ExecuÃ§Ã£o Local (sem Docker)**

### **1. Ativar ambiente virtual**
```bash
# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### **2. Instalar dependÃªncias**
```bash
pip install -r requirements.txt
```

### **3. Executar servidor**
```bash
# OpÃ§Ã£o 1: Executar diretamente
python src/server.py

# OpÃ§Ã£o 2: Executar como mÃ³dulo
python -m src.server
```

## ğŸ“ Estrutura do Projeto

```
local-rag-server/
â”œâ”€â”€ src/                    # CÃ³digo fonte da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ controllers/        # Controladores da API
â”‚   â”œâ”€â”€ models/            # Modelos e schemas
â”‚   â”œâ”€â”€ services/          # ServiÃ§os (RAG, Supabase, etc.)
â”‚   â”œâ”€â”€ routes.py          # Rotas da API
â”‚   â””â”€â”€ server.py          # Servidor FastAPI
â”œâ”€â”€ docker-compose.yml     # OrquestraÃ§Ã£o de containers
â”œâ”€â”€ Dockerfile            # Container da aplicaÃ§Ã£o
â”œâ”€â”€ requirements.txt      # DependÃªncias Python
â””â”€â”€ README.md            # DocumentaÃ§Ã£o
```

## ğŸ—ï¸ Arquitetura

### **Modo Teste:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Qdrant    â”‚    â”‚   Redis     â”‚    â”‚  Supabase   â”‚
â”‚  (Vetores)  â”‚    â”‚   (Cache)   â”‚    â”‚ (PostgreSQL)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Ollama    â”‚    â”‚   FastAPI   â”‚
              â”‚   (IA)      â”‚    â”‚  (Server)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Modo ProduÃ§Ã£o:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Ollama-1  â”‚    â”‚   Ollama-2  â”‚    â”‚   Ollama-3  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Nginx     â”‚    â”‚   FastAPI   â”‚
              â”‚ (Load Bal.) â”‚    â”‚  (Server)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¡ Endpoints da API

### **Receber Mensagem**
```http
POST /message
Content-Type: application/json

{
  "phone_number": "5511999999999",
  "message": "OlÃ¡, como posso ajudar?",
  "message_id": "msg_123",
  "user_name": "JoÃ£o Silva"
}
```

### **Buscar Conversa**
```http
GET /conversation/{phone_number}
```

### **Adicionar Conhecimento**
```http
POST /knowledge
Content-Type: application/json

{
  "documents": ["Texto do documento 1", "Texto do documento 2"],
  "source": "manual"
}
```

## ğŸ¯ Comandos Ãšteis

### **InicializaÃ§Ã£o**
```bash
# Modo teste (1 Ollama)
docker-compose --profile single-ollama up -d

# Modo produÃ§Ã£o (3 Ollamas)
docker-compose --profile multi-ollama up -d

# Parar todos os serviÃ§os
docker-compose down

# Verificar status
docker-compose ps
```

### **Build**
```bash
# Build completo
docker-compose build --parallel

# Build individual
docker-compose build server-test

# Build limpo
docker-compose build --no-cache
```

### **Monitoramento**
```bash
# Verificar status
docker-compose ps

# Ver logs
docker-compose logs -f

# Ver logs de serviÃ§o especÃ­fico
docker-compose logs -f server-test
docker-compose logs -f ollama

# Teste de carga
python monitor_load.py

# Verificar uso de recursos
docker stats
```

### **ManutenÃ§Ã£o**
```bash
# Parar todos os serviÃ§os
docker-compose down

# Parar e remover volumes
docker-compose down -v

# Limpar Docker
docker system prune -a

# Limpar imagens nÃ£o utilizadas
docker image prune -a

# Verificar espaÃ§o em disco
docker system df
```

## ğŸ”§ ConfiguraÃ§Ã£o

### **VariÃ¡veis de Ambiente (.env)**
```bash
# Supabase
SUPABASE_URL=your_supabase_url
SUPABASE_ANON_KEY=your_supabase_key

# WhatsApp API
WTS_API_TOKEN=your_wts_token

# Ollama
OLLAMA_MODEL=llama3.2
OLLAMA_HOST=ollama  # ou nginx para produÃ§Ã£o
OLLAMA_PORT=11434   # ou 80 para produÃ§Ã£o
```

### **Portas Utilizadas**
- **8000**: FastAPI Server
- **6333**: Qdrant (Vetores)
- **6379**: Redis (Cache)
- **54322**: Supabase (PostgreSQL)
- **11434-11436**: Ollama Instances
- **11437**: Nginx Load Balancer

## ğŸ§ª Testes

### **Teste de SaÃºde**
```bash
# Verificar se todos os serviÃ§os estÃ£o rodando
curl http://localhost:8000/docs
curl http://localhost:6333/collections
curl http://localhost:11434/api/tags

# Verificar status dos containers
docker-compose ps

# Verificar logs de inicializaÃ§Ã£o
docker-compose logs --tail=50
```

### **Teste de Carga**
```bash
# Executar teste de performance
python monitor_load.py
```

## ğŸ“Š Performance

### **Modo Teste:**
- **Build Time**: ~5 minutos
- **RAM**: ~4GB
- **ConcorrÃªncia**: Baixa

### **Modo ProduÃ§Ã£o:**
- **Build Time**: ~15 minutos
- **RAM**: ~8GB
- **ConcorrÃªncia**: Alta (3x Ollamas)

## ğŸ› Troubleshooting

### **Build Lento**
```bash
# Windows (CMD)
set DOCKER_BUILDKIT=1
docker-compose build --parallel

# Linux/Mac
export DOCKER_BUILDKIT=1
docker-compose build --parallel
```

### **Erro de Conectividade**
```bash
# Verificar se todos os containers estÃ£o rodando
docker-compose ps

# Verificar logs
docker-compose logs -f

# Verificar logs de erro especÃ­ficos
docker-compose logs server-test
```

### **Problemas de MemÃ³ria**
```bash
# Usar modo teste (menos RAM)
docker-compose --profile single-ollama up -d

# Verificar uso de memÃ³ria
docker stats
```

### **Reconstruir Containers**
```bash
# Reconstruir sem cache
docker-compose build --no-cache

# Reconstruir e iniciar
docker-compose build --no-cache && docker-compose --profile single-ollama up -d
```

## ğŸ“‹ Checklist de InicializaÃ§Ã£o

- [ ] Docker instalado e funcionando
- [ ] Arquivo `.env` criado e configurado
- [ ] Token WTS.chat configurado no `.env`
- [ ] Containers iniciados com sucesso (`docker-compose ps`)
- [ ] API acessÃ­vel em http://localhost:8000/docs
- [ ] Logs sem erros crÃ­ticos (`docker-compose logs`)

## âš ï¸ PrÃ©-requisitos Importantes

1. **Docker e Docker Compose** instalados e funcionando
2. **8GB+ RAM** (recomendado para modo produÃ§Ã£o)
3. **Token da API WTS.chat** para integraÃ§Ã£o WhatsApp
4. **ConexÃ£o com internet** para download das imagens Docker

## ğŸ“ Logs

### **LocalizaÃ§Ã£o dos Logs**
- **Dados**: `./volumes/`
- **Logs Docker**: `docker-compose logs`
- **Logs AplicaÃ§Ã£o**: Console do container

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

---

**Desenvolvido com â¤ï¸ para chatbots inteligentes** 